---
title: "New LLM Model Integration"
description: "Step-by-step guide to integrate new language models into the system for Python, Node.js, and Next.js stacks."
---

<Info>
  **This guide outlines the full integration process for adding a new LLM model**, whether it connects via OpenRouter or directly through SDKs like OpenAI, Claude, Groq, or Mistral.
</Info>

<Steps>

<Step title="Integration Flow Overview">

1. Choose between integration types:
   - **OpenRouter-based**: for models like RAG, Simple Tool Chat, CustomGPT, etc.
   - **Direct SDK-based**: for OpenAI, Claude, Groq, Mistral, etc.
2. Update relevant services, controllers, prompts, SDKs, and model metadata.

</Step>

<Step title="OpenRouter Integration (Python stack)">

- ğŸ“ **Service Layer**: `src/chatflow_langchain/service/`
  - Add folders/files for the model service (e.g., `custom_gpt`, `title`, `simple_chat`)
  
- âš™ï¸ **Controller Logic**: `src/chatflow_langchain/controller/`
  - Update controllers to handle logic and registration via OpenRouter

- âœ¨ **Prompt Templates**: `src/prompt/langchain/`
  - Define or update prompt templates and config for the new model

- ğŸ” **Callbacks**: `src/customlib/langchain/`
  - Implement logic for:
    - MongoDB persistence
    - Token usage tracking
    - Streaming response management

</Step>

<Step title="Direct SDK Integration (Python stack)">

- ğŸ“¦ **Dependencies**: `requirements.txt`
  - Add SDKs like `openai`, `anthropic`, `mistral`, etc.

- âš™ï¸ **Model Config**: `src/chatflow_langchain/service/model/config.py`
  - Add default behavior, token limits, and metadata

- ğŸ§  **Optional Caching**: `chatopenai_cache.py`
  - Add caching, usage tracking, refresh/expiry logic (if OpenAI-specific)

- ğŸ”Œ **Controller Updates**: `src/chatflow_langchain/controller/`
  - Add routing and provider logic

- âœ¨ **Prompt Updates**: `src/prompt/langchain/`
  - Align template tone, structure, and behavior for the model

</Step>

<Step title="Node.js Backend Model Configuration">

- ğŸ“„ **Constants File**: `src/config/constants/aimodal.js`
  - Add new model constant
  - Add to `OPENROUTER_PROVIDER`, `MODAL_NAME`

- ğŸ“„ **Common Constants**: `src/config/constants/common.js`
  - Add model code in `MODEL_CODE`

- ğŸ”‘ **API Key Logic**: `src/services/company.js`
  - Extend `checkApiKey(...)` to support the new model
  - Define a checker function for API validation

</Step>

<Step title="Next.js Frontend Integration">

- ğŸ–¼ï¸ **Model Icon**: Place logo in `public/` directory

- ğŸ”  **Constant Mapping**: `src/utils/constant.ts`
  - Add model code, display name, image path, credit info, and sequence list

- ğŸ§  **Optional Image Feature Support**: `src/utils/helper.ts`
  - If model supports image generation or conversation, update:
    - `allowImageGeneration`
    - `allowImageConversation`

</Step>

<Step title="Database Migration and Model Metadata">

### `Model` Collection

Defines global model metadata:
```json
{
  "title": "Model Name",
  "code": "MODEL_CODE",
  "isActive": true
}
````

### `CompanyModel` Collection

Links model to a company and includes config:

```json
{
  "name": "model-name",
  "bot": {
    "title": "Model Name",
    "code": "MODEL_CODE",
    "id": "ModelCollectionId"
  },
  "company": {
    "name": "Company Name",
    "slug": "company-slug",
    "id": "CompanyId"
  },
  "config": {
    "apikey": "your-api-key"
  },
  "modelType": 2,
  "dimensions": 1536,
  "isActive": true,
  "extraConfig": {
    "stop": [],
    "temperature": 0.7,
    "tools": []
  }
}
```

</Step>

<Step title="Summary of Changes by Path">

| ğŸ“ **Path**                          | ğŸ§  **Purpose**                 |
| ------------------------------------ | ------------------------------ |
| `src/chatflow_langchain/service/`    | ğŸ§© Define services per model   |
| `src/chatflow_langchain/controller/` | ğŸ”— Register & route models     |
| `src/prompt/langchain/`              | âœ¨ Add prompt logic/templates   |
| `src/customlib/langchain/`           | ğŸ” Callbacks & token tracking  |
| `requirements.txt`                   | ğŸ“¦ Add required SDKs           |
| `chatopenai_cache.py`                | ğŸ§  OpenAI-specific cache logic |
| `src/config/constants/`              | ğŸ·ï¸ Node model constants       |
| `src/services/company.js`            | ğŸ”‘ API key checker integration |
| `src/utils/constant.ts`              | ğŸ¨ Model image and metadata    |
| `public/`                            | ğŸ–¼ï¸ Model logos/icons          |

</Step>

</Steps>

<Note>
Always test end-to-end from model selection to final response and cost tracking. Ensure prompt behavior, tool compatibility, and API key validation are functioning as expected.
</Note>

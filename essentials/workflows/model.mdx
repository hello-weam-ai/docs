---
title: "New LLM Model Integration"
description: "Step-by-step guide to integrate new language models into the system for Python, Node.js, and Next.js stacks."
---

<Info>
  **This guide outlines the full integration process for adding a new LLM model**, whether it connects via OpenRouter or directly through SDKs like OpenAI, Claude, Groq, or Mistral.
</Info>

<Steps>

<Step title="Integration Flow Overview">

1. Choose between integration types:
   - **OpenRouter-based**: for models like RAG, Simple Tool Chat, CustomGPT, etc.
   - **Direct SDK-based**: for OpenAI, Claude, Groq, Mistral, etc.
2. Update relevant services, controllers, prompts, SDKs, and model metadata.

</Step>

<Step title="OpenRouter Integration (Python stack)">

- 📁 **Service Layer**: `src/chatflow_langchain/service/`
  - Add folders/files for the model service (e.g., `custom_gpt`, `title`, `simple_chat`)
  
- ⚙️ **Controller Logic**: `src/chatflow_langchain/controller/`
  - Update controllers to handle logic and registration via OpenRouter

- ✨ **Prompt Templates**: `src/prompt/langchain/`
  - Define or update prompt templates and config for the new model

- 🔁 **Callbacks**: `src/customlib/langchain/`
  - Implement logic for:
    - MongoDB persistence
    - Token usage tracking
    - Streaming response management

</Step>

<Step title="Direct SDK Integration (Python stack)">

- 📦 **Dependencies**: `requirements.txt`
  - Add SDKs like `openai`, `anthropic`, `mistral`, etc.

- ⚙️ **Model Config**: `src/chatflow_langchain/service/model/config.py`
  - Add default behavior, token limits, and metadata

- 🧠 **Optional Caching**: `chatopenai_cache.py`
  - Add caching, usage tracking, refresh/expiry logic (if OpenAI-specific)

- 🔌 **Controller Updates**: `src/chatflow_langchain/controller/`
  - Add routing and provider logic

- ✨ **Prompt Updates**: `src/prompt/langchain/`
  - Align template tone, structure, and behavior for the model

</Step>

<Step title="Node.js Backend Model Configuration">

- 📄 **Constants File**: `src/config/constants/aimodal.js`
  - Add new model constant
  - Add to `OPENROUTER_PROVIDER`, `MODAL_NAME`

- 📄 **Common Constants**: `src/config/constants/common.js`
  - Add model code in `MODEL_CODE`

- 🔑 **API Key Logic**: `src/services/company.js`
  - Extend `checkApiKey(...)` to support the new model
  - Define a checker function for API validation

</Step>

<Step title="Next.js Frontend Integration">

- 🖼️ **Model Icon**: Place logo in `public/` directory

- 🔠 **Constant Mapping**: `src/utils/constant.ts`
  - Add model code, display name, image path, credit info, and sequence list

- 🧠 **Optional Image Feature Support**: `src/utils/helper.ts`
  - If model supports image generation or conversation, update:
    - `allowImageGeneration`
    - `allowImageConversation`

</Step>

<Step title="Database Migration and Model Metadata">

### `Model` Collection

Defines global model metadata:
```json
{
  "title": "Model Name",
  "code": "MODEL_CODE",
  "isActive": true
}
````

### `CompanyModel` Collection

Links model to a company and includes config:

```json
{
  "name": "model-name",
  "bot": {
    "title": "Model Name",
    "code": "MODEL_CODE",
    "id": "ModelCollectionId"
  },
  "company": {
    "name": "Company Name",
    "slug": "company-slug",
    "id": "CompanyId"
  },
  "config": {
    "apikey": "your-api-key"
  },
  "modelType": 2,
  "dimensions": 1536,
  "isActive": true,
  "extraConfig": {
    "stop": [],
    "temperature": 0.7,
    "tools": []
  }
}
```

</Step>

<Step title="Summary of Changes by Path">

| 📁 **Path**                          | 🧠 **Purpose**                 |
| ------------------------------------ | ------------------------------ |
| `src/chatflow_langchain/service/`    | 🧩 Define services per model   |
| `src/chatflow_langchain/controller/` | 🔗 Register & route models     |
| `src/prompt/langchain/`              | ✨ Add prompt logic/templates   |
| `src/customlib/langchain/`           | 🔁 Callbacks & token tracking  |
| `requirements.txt`                   | 📦 Add required SDKs           |
| `chatopenai_cache.py`                | 🧠 OpenAI-specific cache logic |
| `src/config/constants/`              | 🏷️ Node model constants       |
| `src/services/company.js`            | 🔑 API key checker integration |
| `src/utils/constant.ts`              | 🎨 Model image and metadata    |
| `public/`                            | 🖼️ Model logos/icons          |

</Step>

</Steps>

<Note>
Always test end-to-end from model selection to final response and cost tracking. Ensure prompt behavior, tool compatibility, and API key validation are functioning as expected.
</Note>
